\newpage
\section{Hilbert Spaces}

\begin{definition}
    \(H\) vector space on \(\real\). A function \(p:H \times H \to \real\) is called \textbf{scalar (or inner) product} if it is positive definite, symmetric, and bilinear; namely if 
    \begin{enumerate}
        \item \(p(x, x) \geq 0\) \(\forall \; x \in H\) and \(p(x, x) = 0 \Rightarrow x=0\)
        \item \(p(x, y) = p(y, x)\) \(\forall \; x, y \in H\)
        \item \(p(\alpha x_1 + \beta x_2, y) = \alpha p (x_1, y) + \beta p(x_2, y)\) \(\forall \; \alpha, \beta \in \real\), \(x_1, x_2, y \in H\)
    \end{enumerate}
\end{definition}

Notation: \(p(x, y) = \langle x, y \rangle = (x, y) = x \cdot y\)

\begin{definition}
    A vector space \(H\) with a scalar product is called a pre Hilbertian space.
\end{definition}

\begin{proposition}
    \((H, \scalardot )\) pre Hilbertian space.
    \begin{itemize}
        \item Cauchy Schwarz inequality \[
            \abs{\langle x, y\rangle} \leq \sqrt{\langle x, x\rangle} \sqrt{\langle y, y\rangle } \quad \forall \; x, y \in H
        \]
        \item \(\sqrt{\langle x, x \rangle} =: \norm{x}\) is a norm on \(H\)
    \end{itemize}
\end{proposition}

\((H, \scalardot)\) pre Hilbert \(\to (H, \normdot)\) normed space \(\to (H, d)\) metric space where \(d(x, y) = \norm{x-y}\)
\subsection{Hilbert spaces}
\begin{definition}
    We say that \((H, \scalardot)\) is a Hilbert space if \((H, \normdot)\) is a Banach space. (namely, if \((H, d)\) is a complete metric space)
\end{definition}
\begin{example}
    \begin{itemize}
        \item \(\real^n\), \(\langle x, y\rangle = \sum_{i=1}^n x_i y_i\)
        \item \(L^2(X, \mathcal{M}, \mu)\) \((X, \mathcal{M}, \mu)\) complete measure space. 
        
        \(\langle f, g\rangle = \int_X fg \, d\mu\). \(\norm{f} = (\int_X f^2 \, d\mu)^\frac{1}{2} = \norm{f}_2\). \((L^2(X), \normdot_2)\) is a Banach space \(\Rightarrow (L^2(X), \scalardot)\) is a Hilbert space.
        \item \(l^2\) is a Hilbert space. \(\langle x, y\rangle = \sum_{k=1}^\infty x^{(k)} y^{(k)}\), \(x = (x^{(k)})\), \(y = (y^{(k)})\)
        \item \((\mathcal{C}^0([a, b]), \scalardot )\) is a pre Hilbertian space. \((\mathcal{C}^0([a, b]), \normdot_2 )\) is not a Banach space. 
    \end{itemize}
\end{example}
\begin{definition}
    \(x, y\) are orthogonal if \(\langle x, y \rangle=0\). We write \(x \perp y\)
\end{definition}
\subsection{Parallelogram identity}
\begin{remark}
    Hilbert spaces are particular cases of Banach spaces. The converse is not true. In any Hilbert space, the norm induced by \(\scalardot\) must satisfy the parallelogram rule
        \begin{equation}\label{parallelogram_rule}
            \norm{x+y}^2 + \norm{x-y}^2 = 2\norm{x}^2 + 2\norm{y}^2 \quad \forall \; x, y \in H \tag*{PR}
        \end{equation}
\end{remark}

\begin{proposition}
    \(H\) Banach space with respect to \(\normdot\). If \(\normdot\) satisfies \eqref{parallelogram_rule}, then \(H\) is a Hilbert space with scalar product 
    \[
        \langle x, y \rangle := \frac{1}{2} [\norm{x+y}^2 - \norm{x}^2 - \norm{y}^2], \quad \langle x,x \rangle = \norm{x}^2
    \]
\end{proposition}

Consequence: we can check that a Banach space is not a Hilbert space by showing that \eqref{parallelogram_rule} does not hold.
Ex: \((L^p, \normdot_p)\) is not a Hilbert space \(\forall\; p \neq 2\). The same for \((\mathcal{C}^0([a, b]), \normdot_\infty )\)

\subsection{Orthogonal projections}

Recall:
\begin{definition}
    \(C \subset H \) is convex if \(\forall\; x, y \in C: \, \frac{x+y}{2} \in C\)
\end{definition}
\begin{definition}
    \(S \subset H\), \(f \in H\). \[ dist (f, S) = \inf_{g \in S} \norm{f-g}\]
\end{definition}

\begin{theorem}[projection on closed convex sets]
    \(H\) Hilbert space. Let \(S \subseteq H\) non-empty, closed, convex. Then \(\forall \; f \in H \quad \exists! \; h \in S\) s.t. 
        \begin{equation}\label{pj_closed_sets}
            \norm{f-h} = dist (f, S) = \min_{g \in S} \norm{f-g} \tag{1}
        \end{equation}
    Moreover, \(h\) is characterized by the variational inequality:
        \begin{equation}\label{pj_dist}
            \langle f-h, g-h \rangle \leq 0 \quad \forall \; g \in S \tag*{*}
        \end{equation}
    namely \(h\) is the projection of \(f \) on \(S\) (\(f\) satisfies \eqref{pj_closed_sets} \(\Leftrightarrow\) \eqref{pj_dist} holds)
\end{theorem}
\begin{remark}
    \(h\) satisfies 1: \(h\) is the projection of \(f\) on \(S\), \(h = P_S f\)
\end{remark}
\begin{proof}
    Only of the existence of \(h\). \\
    \(S \subset H\). \(dist(f, S) >0\) \((f \notin S )\). \(\exists \; \{v_n\} \subset S\) s.t. 
    \[
        \norm{v_n -f} \to d := dist(f, S)    
    \] 
    We show that \(\{v_n\}\) is a Cauchy sequence. Let \(m, n\), then \(\frac{v_m + v_n}{2} \in S\), since \(S\) is convex. Then 
    \[
        \norm{f - \frac{v_m + v_n}{2}} \geq d \Rightarrow \norm{2f - (v_m + v_n)} \geq 2d \tag*{2}
    \]
    By the (PR), with \(x=f-v_n\), \(x=v_m-f\)
    \[
        \norm{v_m - v_n}^2 
        = \norm{v_m \pm f - v_n}^2 
        \overset{PR }{=} \norm{x+y}^2
        = 2\norm{x}^2 + 2 \norm{y}^2 - \norm{x-y}^2 =
    \]
    \[
        = 2 \norm{f-v_n}^2 + 2 \norm{v_m - f }^2 - \norm{2f - (v_m + v_n)}^2
        \overset{(2)}{\leq} 2 \norm{f - v_n}^2 + 2 \norm{v_m - f}^2 - 4d^2 \leq (*)
    \]
    Up to now, we only used that \(v_n , v_m \in S\). Since \(\norm{v_n -f }^2 \to d^2\) as \(n \to \infty\), \(\forall\; \epsilon>0 \) \(\exists \; \overline{n}\) s.t. \(n, m > \overline{n}\)
    \[
        \begin{array}{ll}
            \Rightarrow \norm{v_n - f}^2 < (d+\epsilon)^2 & \norm{v_m - f}^2 < (d+\epsilon)^2
        \end{array}
    \]
    Coming back to \((*)< 4((d+\epsilon)^2 -d^2)\), provided that \(n, m > \overline{n}\). Since \(\epsilon\) was arbitrarily chosen, the right-hand side can be made arbitrary small (it tends to 0 if \(\epsilon \to 0\)). 
    We proved that we can make \(\norm{v_n - v_m}^2\) arbitrarily small, provided that \(n, m\) are sufficiently large.
    
    Namely, \(\{v_n\}\) is Cauchy. Since \((H, \normdot)\) is Banach, \(\exists \; v \in H\) s.t. \(v_n \to v\). \(v \in S\), since \(S\) is closed. And, by continuity, 
    \[
        \norm{f-v} = \lim_n \norm{f - v_n} = d
    \]
    So \(v\) is the desired \(h\).
    
    About uniqueness. \\
    Let \(\overline{v}\) and \(v'\) 2 elements in \(S\) such that
    \[
        \norm{f- \overline{v}} = \norm{f - v'} = d
    \]
    Then, exactly as before, 
    \[
        \norm{\overline{v} - v'}^2 = 2(\norm{\overline{v} - f}^2 + \norm{v' -f}^2) - \norm{2f - (\overline{v}+v')}^2 \leq 2 (d^2+d^2)-4d^2 = 0
    \]
    \(\Rightarrow \overline{v} = v'\)
\end{proof}

\begin{remark}
    A particular case: \(S\) closed subspace (it is always convex). In this case, the variational inequality becomes an equality:
    \[
        h = P_S f \Leftrightarrow \langle f-h, g\rangle = 0 \quad  \forall \; g \in S
    \]
\end{remark}


\begin{definition}
    \(H\) Hilbert space. \(S \subset H\) subset. We define the \textbf{orthogonal complement} of \(S\) as 
    \[
        S^\perp = \{ x \in H:  \langle x, y\rangle = 0 \quad \forall\; y \in S\}
    \]
\end{definition}
\begin{example}
    \(S^\perp \) is always a closed subspace of \(H\)
\end{example}
\begin{example}
    If \(S\) is a subspace, then \(S \cap S^\perp = \{0\}\)
\end{example}

\begin{definition}
    \(V, W\) subspace of \(H\), orthogonal one to each other:
    \[
        \forall \; v \in V, \quad w \in W: v \perp w
    \]
    We can define the \textbf{orthogonal sum} of \(V\) and \(W\) as 
    \[
        V \oplus W = \{ v+w : v \in V, w \in W \}
    \]
\end{definition}
\begin{example}
    If \(x \in V \oplus W \Rightarrow \exists! \; (v, w) \in V \times W\) s.t. \(x=v+w\)
\end{example}

\begin{theorem}
    \(H\) Hilbert space. Let \(V \subseteq H\) be a closed subspace. Then 
    \[
        H = V \oplus V^\perp
    \]
\end{theorem}

\begin{definition}
    From the theorem, given any \(x \in H\) we can define
    \[
        \begin{array}{rl}
            P_v: & H \to V \\
            & x = v + w \mapsto v \\ \tag*{orthogonal projections}
            P_{v^\perp} : & H \to V^\perp \\
            & x \mapsto w
        \end{array}
    \]
\end{definition}
\begin{example}
    \(P_v \) and \(P_{v^\perp}\) are linear bounded operators, with norms 1.
\end{example}
\subsection{Dual space of a Hilbert space}
Observe that, if \(y \in H\), then we can define \(\Lambda_y : H \to \real\) as
\[
    \Lambda_y x = \langle y, x\rangle  
\]
It is linear (\(\scalardot   \) is bilinear), and it is bounded: 
\[
    \abs{\Lambda_y x}= \abs{\langle y, x\rangle  } \leq \norm{y} \norm{x} \quad \forall\; x, y
\]
\(\Rightarrow \Lambda_y\) is bounded, with \(\norm{\Lambda_y}_* \leq \norm{y}\)

Moreover, 
\[
    \Lambda_y \left(\frac{y}{\norm{y}}\right) = \langle y, \frac{y}{\norm{y}}\rangle   = \norm{y}
\]
\[
    \Rightarrow \norm{\Lambda_y}_* = \sup_{\norm{x} \leq 1} \abs{\Lambda_y x} \geq \abs{\Lambda_y \left(\frac{y}{\norm{y}}\right)} = \norm{y}
\]
Thus \( \norm{\Lambda_y}_* = \norm{y}\), and the map 
\[
    \begin{array}{rl}
        i: & H \to H^* \\
        & y \mapsto \Lambda_y    
    \end{array}
\]
is an isometry from \(H\) into \(i(H) \subset {H^*}\).

Are there other elements in \(H^*\)?
\subsection{Riesz's representation theorem}
\begin{theorem}[Riesz Representation Theorem]
    \(\forall \; \Lambda \in H^* \) \(\exists! \; y \in H\) s.t. \(\Lambda = \Lambda_y\), namely
    \[
        \Lambda x = \langle y, x\rangle   \qquad \forall x \in H
    \]
    Moreover, the map \(i\) is an isometric isomorphism. We can identify \(H^*\) with \(H\)
\end{theorem}

\begin{corollary}
    Any Hilbert space is reflexive. 
\end{corollary}
\begin{remark}
    Any Hilbert space is uniformly convex.
\end{remark}

\begin{itemize}
    \item Riesz in \(L^p\): \(L^p \) is uniformly convex \(\Rightarrow L^p\) is reflexive. We used this fact to prove Riesz in \(L^p\)
    \item Riesz in Hilbert: direct proof of \(H^* = H \Rightarrow H\) is reflexive.
\end{itemize}
Both strategies can be adopted in both contexts.

\begin{proof}
    \begin{itemize}
        \item We show that \(\forall\; \Lambda \in H^* \) \(\exists\; y \in H\) s.t. \(\Lambda = \Lambda_y\)
        
        If \(\Lambda = 0 \Rightarrow \Lambda = \Lambda_0\) \((\Lambda_0 x = \langle 0, x\rangle   = 0)\)

        Suppose \(\Lambda \neq 0. \) \(\ker(\Lambda) = \Lambda^{-1}(\{0\}) \) is a closed (since \(\Lambda\) is continuous) subspace, \(\neq H\). \(\Rightarrow\) we consider \(\ker(\Lambda)^\perp \neq \{0\}\). Let
        \[
            z \in \ker(\Lambda)^\perp, \quad \norm{z}=1
        \]
        For \(x \in H\), we have
        \[
            x - \frac{\Lambda x}{\Lambda z} z \in \ker(\Lambda)
        \]
        Indeed, \(\Lambda \left( \frac{\Lambda x}{\Lambda z} z \right) \overset{linearity}{=} \Lambda x - \frac{\Lambda x}{\Lambda z} \Lambda z = 0\). Then, since \(z\) is orthogonal to any element of \(\ker(\Lambda)\), 
        \[
            \langle z, x - \frac{\Lambda x}{\Lambda z} z\rangle   = 0 \qquad \forall\; x \in H
        \] 
        \(\scalardot  \) is bilinear: the left-hand side is 
        \[
            \langle z, x\rangle   - \frac{\Lambda x}{\Lambda z} \norm{z}^2 \Rightarrow \langle z, x\rangle   = \frac{\Lambda x}{\Lambda z} 
        \]
        \[
            \Lambda x = \langle (\Lambda z)z, x\rangle   \qquad \forall \; x \in H
        \]
        So the thesis is proved for \(y = (\Lambda z)z\).

        \item The uniqueness of \(y\) is easy.
        \[
            \langle x, y_1\rangle   = \langle x, y_2\rangle   \quad \forall \; x \in H
        \]
        Then \(\langle x, y_1-y_2\rangle   = 0\) \(\forall \; x \in H\). We choose \(x = y_1 -y_2\):
        \[
            \norm{y_1 - y_2}^2 = 0 \Rightarrow y_1 = y_2
        \]
    \end{itemize}
\end{proof}
\subsection{Convergences}
Consequence: \(H\) Hilbert space.
\[
    x_n \rightharpoonup x \text{ in } H \Leftrightarrow \langle x_n, y\rangle   \to \langle x, y\rangle   \quad \forall\; y \in H
\]
Sometimes weak convergence + something else \(\Rightarrow\) strong convergence. For instance
\begin{proposition}
    \(H\) Hilbert. If \(x_n \rightharpoonup x\)  in \(H\), and \(\norm{x_n} \to \norm{x}\) \(\Rightarrow x_n \to x\) in \(H\), namely \(\norm{x_n - x} \to 0\)
\end{proposition}
\begin{proof}
    \[
        \norm{x_n - x }^2 = \norm{x_n}^2 - 2 \langle x_n, x\rangle   + \norm{x}^2 = (*)
    \]
    \(\langle x_n, x\rangle   \to \langle x, x\rangle   = \norm{x}^2 \) by weak convergence.
    \[
        (*) = \norm{x}^2 - 2 \norm{x}^2 + \norm{x}^2 = 0
    \]
\end{proof}

\subsection{Orthonormal Basis}

In \(\real^n\), we have the canonical basis
\[
    e_1, ..., e_n \in \real^n
\]
s.t.
\[
    e_j^{(k)} = 
    \begin{cases}
        1 & k=j \\
        0 & k \neq j   
    \end{cases}
\]
There elements are \(\perp\): \(\langle e_i, e_j\rangle   = 0\) \(\forall\; i \neq j\). \(\norm{e_i}=1\) \(\forall\; i\).

Moreover, \(e_1, ..., e_n\) are a basis, namely \(\forall\; v \in \real^n\) \(\exists! \;\) expression
\[
    v = \sum_{i=1}^n v_i e_i = \sum_{i=1}^n \langle v, e_i\rangle   e_i
\]
In particular, \(v=0 \Leftrightarrow \langle v, e_i\rangle  = 0\) \(\forall\; i\). Do we have an analogue in Hilbert spaces?

\begin{definition}
    \(S \subset H\) is called orthonormal if 
    \begin{itemize}
        \item \(x \perp y\) \(\forall\; x \neq y\), \(x\), \(y \in S\)
        \item \(\norm{x} = 1\) \(\forall x \in S\)
    \end{itemize}
\end{definition}
\begin{definition}
    An orthonormal set is a Hilbert Basis (or is \textbf{complete}) if \(S^\perp = \{0\}\), namely if 
    \[
        \langle u, x\rangle   = 0 \quad \forall x \in S \Rightarrow u=0
    \]
\end{definition}
\begin{theorem}
    \(H\) Hilbert space, \(H \neq \{0\}\). Then \(H\) has a Hilbert basis.

\noindent Moreover, \(H\) is a separable Hilbert space \(\Leftrightarrow \) it has a finite and countable Hilbert basis.
\end{theorem}
\begin{example}
    \begin{itemize}
        \item \(H = l^2\). \(H\) is separable
        
        An Hilbert basis is \(\{e_n\}_{n \in \natural}\) defined By
        \[
            e_n^{(k)} = 
            \begin{cases}
                1 & k=n \\
                0 & k \neq n
            \end{cases}
        \]
    
        \item \(H = L^2([-\pi, \pi])\)
        
        An Hilbert basis is
        \[
            \lbrace \frac{1}{\sqrt{2\pi}}, \frac{\sin(nx)}{\sqrt{\pi}}, \frac{cos(nx)}{\sqrt{\pi}} \rbrace \quad n \in \natural
        \]
    \end{itemize}
\end{example}
\begin{remark}
    Hamel basis \(\neq\) Hilbert basis.

    \(X \; \infty-\) dimensional \(\Rightarrow\) any Hamel basis of \(X\) is uncountable.

    \(H \; \infty-\) dimensional and separable \(\Rightarrow\) any Hilbert basis is countable
\end{remark}

The usefulness of Hilbert basis stays in the fact that they allow us to reason component by component.
\subsection{Bessel inequality}
\begin{theorem}[Bessel inequality]
    \(H\) separable Hilbert space. \(\{u_n\}_{n \in \natural}\) orthonormal set. Then \(\forall \; x \in H\):
    \[
        \sum_{n=1}^\infty \abs{\langle x, u_n\rangle }^2 \leq \norm{x}^2
    \]
\end{theorem}
\begin{theorem}[Generalized Fourier Series]
    \(H\) separable Hilbert space, \(\{u_n\}\) Hilbert basis.
    Then any \(x \in H\) can be written in a unique way as 
    \[
        x = \sum_{n=1}^\infty \langle x, u_n\rangle   u_n \qquad \langle x, u_n\rangle   \text{ Fourier coefficient of }x
    \]
    Moreover, \(\forall\; y \in H\) we have
    \[
        \langle x, y\rangle   = \sum_{n=1}^\infty \langle x, u_n\rangle   \langle y, u_n \rangle  
    \]
    and 
    \[
        \norm{x}^2 = \sum_{n=1}^\infty (\langle x, u_n\rangle  )^2 \tag*{Parseval identity}
    \]
\end{theorem}
\subsection{Riesz-Fisher theorem}
\begin{theorem}
    \(H\) separable Hilbert space. Then \(H\) is isomorphic to \(l^2\) as Hilbert space: namely \(\exists\) an isomorphism \(\phi: H \to l^2\) s.t.
    \[
        \langle x, y\rangle  _H = \langle \phi(x), \phi(y)\rangle  _{l^2} \qquad \forall x, y \in H
    \]
\end{theorem}
\begin{proof}
    \(\exists\) a countable Hilbert basis, and \(\forall\; x \in H\)
    \[
        x = \sum_{n=1}^\infty \langle x, u_n\rangle   u_n
    \]
    Then the desired isomorphism is
    \[
        \begin{array}{rl}
            \phi: & H \to l^2 \\
            & x \mapsto \sum_{n=1}^\infty \langle x, u_n\rangle   e_n
        \end{array}
    \]
\end{proof}

\begin{corollary}
    \(H\) separable Hilbert space, \(\dim H = \infty\). \(\{u_n\}_{n \in \natural}\) Hilbert basis. Then \(u_n \rightharpoonup 0\)  in \(H\), but \(u_n \nrightarrow 0\) in \(H\).
\end{corollary}
\begin{proof}
    \[
        \norm{u_n}=1 \quad \forall\; n \Rightarrow \norm{u_n -0} \nrightarrow 0 
    \]
    On the other hand, we know that \(\forall \; x \in H\)
    \[
        \norm{x}^2 = \sum_{n=1}^\infty \abs{\langle x, u_n\rangle  }^2 < \infty
    \]
    It is then necessary that
    \[
        \langle x, u_n\rangle   \to 0 \text{ as } n \to \infty \qquad \forall\; x \in H
    \]
    By Riesz, this means that \(u_n \rightharpoonup 0\) in \(H\)
\end{proof}

\begin{example}
    \(H = L^2([-\pi, \pi])\). Then the previous corollary tells that (Riemann - Lebesgue lemma)
    \[
        \int_{-\pi}^\pi f(x) \sin (nx) \, dx \to 0 \text{ as } n \to \infty
    \]                
    \(\sin(nx) \rightharpoonup 0\) in \(L^2([-\pi, \pi])\) as \(n \to \infty\). Note that \(\{sin(nx)\}_{n \in \natural}\) does not converge for a.e. \(x\).
    
    Weak convergence in \(L^2\) and pointwise or a.e. convergence are not related.
    
    \(\{sin(nx)\}\) does not converge a.e. on \([-\pi, \pi]\), not even up to subsequences. 
    The same is true in \(L^p\), \(p \neq 2\). Even in this case
    \[
        \sin(nx) \rightharpoonup 0 \text{ in } L^p([a,b]) \quad (p \in [1, \infty),
    \] 
    but we don't have a.e. convergence.
\end{example}